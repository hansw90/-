
#크롤링(Crawling)
1. 특정 페이지에 있는 정보들을 내가 원하는 포맷으로 가져오는것
2. WebScrapping을 자동으로 돌아다니며 분석 및 저장등을 하는 행위 정도로 저장할수 있습니다.

쉽게 생각하는 크롤링(Crawling)
- 사람들이 웹페이지에 직접 접속해서 정보를 읽어드리는 것과 유사
- 인터넷상에 흩어져 있는 자료들을 사람 대신에 프로그램을 통하여 서핑하며 수집과 가공을 하는것
- 이때 프로그램 구성에 따라 서핑능력의 차이가 발생하게 되는데 대표적으로 자바스크립트의 처리를 하는지 못하는지의 여부가 있습니다.


#크롤링을 하기전 알아야하는 지식
#HTTP 매서드
- GET: 리소스 요청 (크롤링에 주로 사용) => 받아드리는 녀석
- POST: 대기 리소스 추가 요청이나 수정/삭제 목적으로 사용(크롤링에 주로 사용) => 내가 추가로 요청하는 녀석
- PUT: 리소스 수정 요청
- DELETE: 리소스 삭제 요청
- HEAD: HTTP헤더 정보만 요청. 해당 자원의 존재여부를 확인하기 위한 목적
- OPTIONS: 웹서버가 지원하는 매서드 종류 반환 요청
- TRACE: 클라이언트의 요청을 그대로 반환 (여기서 클라이언트느 사용자를 말하겠죠?)

GET/POST ?
@GET
- 엽서(실생활에서 편지만 보낼수 있는 엽서에 비유)
- 주소와 함께 메시지를 남김
- 물건을 보낼 수 없다(파일 업로드 불가)
- 잘 설계된 서비스라면 주로 조회 요청시 사용
@POST
- 택배(실생활에서 편지를 포함한 여러 물건도 보낼수 있는 택배에 비유)

- 주소와 함께 메시지나 물건도 보낼 수 있음

- 파일업로드를 지원

- 잘 설계된 서비스에서 주로 추가/수정/삭제 요청시에 사용



## HTTP 요청/응답 패킷 형식
@ 요청패킷
- 요청헤더: 클라이언트에서 필요한 헤더 Key/Value를 세팅한 후 요청, 전달
- 첫번째 빈줄: Header와 Body 구분자
- Body: 클라이언트에서 필요한 Body를 세팅한 후 요청, 전달
@ 응답패킷
- 응답헤더: 서버에 필요한 Key/Value를 세팅한 후, 응답, 전달

- 첫번째 빈줄: Header와 Body 구분자

- Body: 서버에서 필요한 Body를 세팅한 후 요청, 전달



@ 요청패킷 vs 응답패킷
- 요청헤더는 클라이언트에서 필요한 헤더 Key/Value를 세팅한후 요청 전달 하지만,
  응답헤더는 서버         에    필요한       Key/Value를 세팅한후 응답 전달 한다.

- 쉽게 생각하면 클라이언트는 사용자 이기 때문에 당연히 서버에게 요청을 할것이고 서버는 서비스를 하는 업체 입장이기 떄문에 응답을 해주는 것이다.
클라이언트 - 요청 (음식점의 주문) vs 서버는 응답(주문을 받아 알맞은 음식을 서빙)

@ 헤더(Header)란?
- HTTP요청/응답 시에 헤더 정보가 Key/Value 형식으로 세팅이 된다.
- 대개 브라우저에서는 다음 헤더를 설정하는데,
- User-Agent: 브라우저의 종류
- Referer: 이전 페이지 URL(어떤 페이지를 거쳐서 왔는가?)
- Accept-Language: 어떤 언어로 응답을 원하는가?
- Authorization: 인증 정보
- 크롤링을 할떄는 User-Agent헤더와 Referer를 커스텀하게 설정할 필요가 있다.
- 서비스에 따라 UserAgent헤더와 Referer헤더를 통해 응답을 거부하기도 함
ex) 네이버 웹툰.

@Body란?
- HTTP 요청시에는 Body가 없고, 응답에만 있음(서버에서 응답을 줄때만 있는게 맞겠죠?)
Ex)HTML코드, 이미지데이터, JavaScript코드, CSS코드, 비디오 데이터 등등..


출처: https://rednooby.tistory.com/96?category=695414 [개발자의 취미생활]
